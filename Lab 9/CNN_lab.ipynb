{"cells":[{"metadata":{},"cell_type":"markdown","source":"## You should perform this lab in Kaggle. The good news is that you can use the dataset already present in kaggle following this link:\nhttps://www.kaggle.com/nafisur/dogs-vs-cats"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input/dataset/dataset\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"['training_set', 'test_set', 'sample']\n","name":"stdout"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"},"cell_type":"markdown","source":"### set a string variable 'wd' for working directory to '../input/dataset/dataset'"},{"metadata":{"trusted":true},"cell_type":"code","source":"wd = '../input/dataset/dataset'","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"290a62b7e97810f0f5afaa58917693ed323e2712"},"cell_type":"markdown","source":"## Convolutional Neural Network\n\n### Part 1 - Building the CNN\n\nImporting the Keras libraries and packages:\nSequential, Conv2D, MaxPooling2D, Flatten and Dense"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense","execution_count":3,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"_uuid":"473b11511ebc2922b178476d3ff94b49beaaccd4"},"cell_type":"markdown","source":"# Initialize the CNN\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"cnn = Sequential()","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Step 1 - Convolution\nadd a convolution layer with 32 units 3x3 shape. The input shape for the images is 64x64x3 and the activation layer 'relu'"},{"metadata":{"trusted":true},"cell_type":"code","source":"cnn.add(Conv2D(32, kernel_size=3, activation=\"relu\", input_shape=(64,64,3)))","execution_count":5,"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Step 2 - Pooling\nadd a pooling layer for Max Pooling with a pool size of 2 by 2"},{"metadata":{"trusted":true},"cell_type":"code","source":"cnn.add(MaxPooling2D(pool_size=(2,2)))","execution_count":6,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Adding a second convolutional layer which should be similar to the first one except one thing"},{"metadata":{},"cell_type":"markdown","source":"### Step 3 - Flattening\nadd a Flatten layer"},{"metadata":{"trusted":true},"cell_type":"code","source":"cnn.add(Flatten())","execution_count":7,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Step 4 - Full connection"},{"metadata":{},"cell_type":"markdown","source":"Add two Dense layers with 128 and 1 units respectively. The first layer should cut off the negative values, whereas the second layer should return the classes in form of probabilities. Could you guess which activation functions are these?"},{"metadata":{"_uuid":"15c9509a2a5ec105d7c6dcf4c0d13911bca8ed68","trusted":true},"cell_type":"code","source":"cnn.add(Dense(units=(128), activation=\"relu\"))\ncnn.add(Dense(units=(1), activation=\"sigmoid\"))","execution_count":8,"outputs":[]},{"metadata":{"_uuid":"531b0ef3cd64af6ce344029c93e1771d759ac6f0"},"cell_type":"markdown","source":"### Compiling the CNN\ncompile the network with 'adam' optimizer, binary_crossentropy as a loss and accuracy as metrics"},{"metadata":{"trusted":true},"cell_type":"code","source":"cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","execution_count":9,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Augment the images. The code is given"},{"metadata":{"_uuid":"041573842d4af7ba81413d61f4d0e5f632d38fc2","trusted":true},"cell_type":"code","source":"# Part 2 - Fitting the CNN to the images\n\nfrom keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale = 1./255,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\n\ntest_datagen = ImageDataGenerator(rescale = 1./255)\n\ntraining_set = train_datagen.flow_from_directory(wd+'/training_set',\n                                                 target_size = (64, 64),\n                                                 batch_size = 32,\n                                                 class_mode = 'binary')\n\ntest_set = test_datagen.flow_from_directory(wd+'/test_set',\n                                            target_size = (64, 64),\n                                            batch_size = 32,\n                                            class_mode = 'binary')","execution_count":10,"outputs":[{"output_type":"stream","text":"Found 8000 images belonging to 2 classes.\nFound 2000 images belonging to 2 classes.\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Fit the classifier"},{"metadata":{"_uuid":"d55612de7e3d9c3996e9e65c3dd1a9bfec208074","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Perform the training"},{"metadata":{"_uuid":"c272fea5df360f5699c6d579fcc6463133d3538c","trusted":true},"cell_type":"code","source":"cnn.fit_generator(training_set,\n                         steps_per_epoch = 8000,\n                         epochs = 3,\n                         validation_data = test_set,\n                         validation_steps = 2000, use_multiprocessing=True)","execution_count":11,"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nEpoch 1/3\n8000/8000 [==============================] - 2141s 268ms/step - loss: 0.4531 - acc: 0.7791 - val_loss: 0.6341 - val_acc: 0.7525\nEpoch 2/3\n8000/8000 [==============================] - 2101s 263ms/step - loss: 0.2612 - acc: 0.8884 - val_loss: 0.9434 - val_acc: 0.7415\nEpoch 3/3\n8000/8000 [==============================] - 2059s 257ms/step - loss: 0.1726 - acc: 0.9302 - val_loss: 1.1282 - val_acc: 0.7482\n","name":"stdout"},{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"<keras.callbacks.History at 0x7f0a49dda390>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Make a single prediction. The code is given"},{"metadata":{"_uuid":"361421cfe668693bf91e2570326af8293587b004","trusted":true},"cell_type":"code","source":"# Part 3 - Making new predictions\n\nimport numpy as np\nfrom keras.preprocessing import image\ntest_image = image.load_img(wd+'/sample/cat_or_dog_1.jpg', target_size = (64, 64))\ntest_image = image.img_to_array(test_image)\ntest_image = np.expand_dims(test_image, axis = 0)\nresult = cnn.predict(test_image)\ntraining_set.class_indices\nif result[0][0] == 1:\n    prediction = 'dog'\nelse:\n    prediction = 'cat'","execution_count":13,"outputs":[]},{"metadata":{"_uuid":"4affb1bb66b0456c36606ad7dc033b165d8409c9","trusted":true},"cell_type":"code","source":"print(prediction)","execution_count":14,"outputs":[{"output_type":"stream","text":"dog\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"nbformat":4,"nbformat_minor":1}